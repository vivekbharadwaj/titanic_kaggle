{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What I want to achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my current knowledge of python and machine learning, I want to be able to run an ensemble to algos to predict titanic survival. Gosh, we're still into that. I hope I dont ever have to touch this or the iris dataset in a years time...Thanks to [Bugra Akyildiz](http://bugra.github.io/work/notes/2014-11-22/an-introduction-to-supervised-learning-scikit-learn/) for a great blog on supervised learning. Check it out and weep with joy!\n",
    "\n",
    "Ok, so what do we need to do? - Binary classification of survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admin stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) # Display any number of columns\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "# Set seaborn aesthetic parameters to defaults\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling from the lessons learned during the exploratory session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    61.616162\n",
       "1    38.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the class distribution of the response variable\n",
    "train.Survived.value_counts()/train.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 60:40 split. Looks cool to me. No class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 891\n"
     ]
    }
   ],
   "source": [
    "# quick test to see if passenger id is indeed unique and can be used as the index\n",
    "print len(train.PassengerId), len(train.PassengerId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# fill up age variable with righteous values i.e. median age\n",
    "print train.Age.isnull().sum()\n",
    "train['Age'].fillna(train['Age'].median(), inplace = True)\n",
    "print train.Age.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# check out SibSp and Parch features\n",
    "print train.SibSp.isnull().sum()\n",
    "print train.Parch.isnull().sum()\n",
    "print train.Fare.isnull().sum()\n",
    "print train.Embarked.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      32.204208\n",
       "std       49.693429\n",
       "min        0.000000\n",
       "25%        7.910400\n",
       "50%       14.454200\n",
       "75%       31.000000\n",
       "max      512.329200\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Fare.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Embarked.value_counts()\n",
    "\n",
    "# most of them seem to be from Southampton S, so encode the 2 remaining null values as 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 pax dont have cabin level information\n",
      "0 pax are travelling ticketless. However,....\n",
      "210 pax are travelling on another passengers tickets.\n"
     ]
    }
   ],
   "source": [
    "# check how many rows have cabin level information\n",
    "print train.Cabin.isnull().sum(), \"pax dont have cabin level information\"\n",
    "\n",
    "# what about ticket info\n",
    "print train.Ticket.isnull().sum(), \"pax are travelling ticketless. However,....\"\n",
    "\n",
    "# however, multiple people could be travelling on the same ticket. Lets see if thats the case\n",
    "print len(train.Ticket) - len(train.Ticket.drop_duplicates()), \"pax are travelling on another passengers tickets.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to do the data cleansing for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def titanic_wrangling(raw_dataset):\n",
    "    \n",
    "    # convert the passengerid column into index. I've already checked that this field is unique per row.\n",
    "    clean_dataset = raw_dataset.set_index('PassengerId', drop=True)\n",
    "    \n",
    "    # there's heaps of null ages. I got this from the exploratory session in the previous workbooks. Fill with \n",
    "    # median age of the passengers\n",
    "    clean_dataset['Age'].fillna(clean_dataset['Age'].median(), inplace = True)\n",
    "    \n",
    "    # theres 2 null embarked rows. I'm coding these as 'S' fo reasons described above\n",
    "    clean_dataset['Embarked'].fillna('S', inplace = True)\n",
    "  \n",
    "    # Encode string values into discrete integers\n",
    "    #import & instantiate\n",
    "    from sklearn import preprocessing\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    # fit & transform SEX variable into discrete integer values\n",
    "    clean_dataset['Sex'] = label_encoder.fit_transform(clean_dataset['Sex'])\n",
    "    # fit & transform EMBARKED variable into discrete integer values\n",
    "    clean_dataset['Embarked'] = label_encoder.fit_transform(clean_dataset['Embarked'])\n",
    "    # fit & transform TICKET variable into discrete integer values. Given 210 pax have dup tickets, this could be \n",
    "    # predictive.\n",
    "    clean_dataset['Ticket'] = label_encoder.fit_transform(clean_dataset['Ticket'])\n",
    "    \n",
    "    # Get the response variable as a numpy matrix\n",
    "    label = clean_dataset['Survived'].as_matrix().astype(int)\n",
    "    \n",
    "    # Drop redundant columns from the clean dataset\n",
    "    # note that I'm removing the cabin information for now, because there is too much scope for overfitting here \n",
    "    # notice also that I'm dropping Survived because I've already created the response variable\n",
    "    clean_dataset.drop(['Name','Cabin','Survived'], axis=1, inplace=True)\n",
    "    \n",
    "    features = clean_dataset.as_matrix().astype(np.float)\n",
    "    \n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Future Improvement #1:__ Note here that encoding categorical features into integers has introduced implicit ordering in the Sex and Ticket variable. Strings are not inherently ordered, but integers are. We could transform these string features by creating dummy features. This can be achieved by: <br\\> a) using sklearn.preprocessing.OneHotEncoder, or <br\\> b) using the pandas method pd.get_dummies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the data wrangling function to give us our features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 8) (891,)\n"
     ]
    }
   ],
   "source": [
    "X, y = titanic_wrangling(train)\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3.    ,    1.    ,   22.    , ...,  523.    ,    7.25  ,    2.    ],\n",
       "       [   1.    ,    0.    ,   38.    , ...,  596.    ,   71.2833,    0.    ],\n",
       "       [   3.    ,    0.    ,   26.    , ...,  669.    ,    7.925 ,    2.    ],\n",
       "       ..., \n",
       "       [   3.    ,    0.    ,   28.    , ...,  675.    ,   23.45  ,    2.    ],\n",
       "       [   1.    ,    1.    ,   26.    , ...,    8.    ,   30.    ,    0.    ],\n",
       "       [   3.    ,    1.    ,   32.    , ...,  466.    ,    7.75  ,    1.    ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the features are clearly in need of some scaling and standardisation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBC..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7_titanic_kaggle",
   "language": "python",
   "name": "titanic_kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
